{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfATAx6UnDHzSpfhFw07E+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rami2ee3/DA_study/blob/main/boram_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAAMW3yyKtaq",
        "outputId": "199b1790-93e8-491a-a77f-61d3227ff47a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] 수치형 컬럼: 23\n",
            "label_역률평균 NaN 개수: 0\n",
            "label_전류고조파평균 NaN 개수: 0\n",
            "label_전압고조파평균 NaN 개수: 0\n",
            "[INFO] X_train: (2420565, 23) y_train: (2420565, 3) X_test: (313267, 23)\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.227960 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5791\n",
            "[LightGBM] [Info] Number of data points in the train set: 1936452, number of used features: 23\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Validation Report: label_역률평균 ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9919    0.9512    0.9711    263476\n",
            "           1     0.6605    0.9423    0.7766     30875\n",
            "           2     0.9931    0.9806    0.9868    189762\n",
            "\n",
            "    accuracy                         0.9622    484113\n",
            "   macro avg     0.8818    0.9580    0.9115    484113\n",
            "weighted avg     0.9712    0.9622    0.9649    484113\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.138518 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5791\n",
            "[LightGBM] [Info] Number of data points in the train set: 1936452, number of used features: 23\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Validation Report: label_전류고조파평균 ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9977    0.9825    0.9901    390961\n",
            "           1     0.9175    0.9673    0.9417     78104\n",
            "           2     0.8818    0.9839    0.9300     15048\n",
            "\n",
            "    accuracy                         0.9801    484113\n",
            "   macro avg     0.9323    0.9779    0.9539    484113\n",
            "weighted avg     0.9812    0.9801    0.9804    484113\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.142796 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5791\n",
            "[LightGBM] [Info] Number of data points in the train set: 1936452, number of used features: 23\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Validation Report: label_전압고조파평균 ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9285    0.9107    0.9195    198717\n",
            "           1     0.8102    0.8550    0.8320    138719\n",
            "           2     0.9374    0.9128    0.9249    146677\n",
            "\n",
            "    accuracy                         0.8954    484113\n",
            "   macro avg     0.8920    0.8928    0.8922    484113\n",
            "weighted avg     0.8973    0.8954    0.8961    484113\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Saved: predictions_model_clean.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# =========================\n",
        "# 1️⃣ 데이터 불러오기\n",
        "# =========================\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/elecClassification_train/train.csv\", encoding=\"utf-8\")\n",
        "test  = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/elecClassification_test/test.csv\", encoding=\"utf-8\")\n",
        "\n",
        "# =========================\n",
        "# 2️⃣ 전처리: 결측치/피처 준비\n",
        "# =========================\n",
        "# 불필요한 컬럼 제거\n",
        "for df in [train, test]:\n",
        "    for col in [\"index\", \"ID\", \"Id\"]:\n",
        "        if col in df.columns:\n",
        "            df.drop(columns=[col], inplace=True)\n",
        "\n",
        "# 수치형 컬럼만 추출\n",
        "num_cols = [c for c in train.select_dtypes(include=np.number).columns]\n",
        "print(f\"[INFO] 수치형 컬럼: {len(num_cols)}\")\n",
        "\n",
        "# 결측치 채우기 (중앙값)\n",
        "train[num_cols] = train[num_cols].fillna(train[num_cols].median())\n",
        "test[num_cols]  = test[num_cols].fillna(train[num_cols].median())  # train 기준 median\n",
        "\n",
        "# =========================\n",
        "# 3️⃣ 파생 피처: 상별 전력 합/역률, 총전력\n",
        "# =========================\n",
        "for phase in [\"R\",\"S\",\"T\"]:\n",
        "    train[f\"{phase}전력합\"] = np.sqrt(train[f\"{phase}상유효전력\"]**2 + train[f\"{phase}상무효전력\"]**2)\n",
        "    train[f\"{phase}역률\"] = train[f\"{phase}상유효전력\"] / train[f\"{phase}전력합\"]\n",
        "\n",
        "train[\"총전력합\"] = train[\"R전력합\"] + train[\"S전력합\"] + train[\"T전력합\"]\n",
        "\n",
        "# 동일 피처를 test에도 생성\n",
        "for phase in [\"R\",\"S\",\"T\"]:\n",
        "    test[f\"{phase}전력합\"] = np.sqrt(test[f\"{phase}상유효전력\"]**2 + test[f\"{phase}상무효전력\"]**2)\n",
        "    test[f\"{phase}역률\"] = test[f\"{phase}상유효전력\"] / test[f\"{phase}전력합\"]\n",
        "test[\"총전력합\"] = test[\"R전력합\"] + test[\"S전력합\"] + test[\"T전력합\"]\n",
        "\n",
        "# =========================\n",
        "# 4️⃣ 라벨 매핑\n",
        "# =========================\n",
        "label_cols = [\"label_역률평균\",\"label_전류고조파평균\",\"label_전압고조파평균\"]\n",
        "label_map  = {\"정상\":0, \"주의\":1, \"경고\":2}\n",
        "\n",
        "for col in label_cols:\n",
        "    train[col] = train[col].astype(str).str.strip()\n",
        "    train[col] = train[col].map(label_map)\n",
        "\n",
        "# NaN 확인\n",
        "for col in label_cols:\n",
        "    print(f\"{col} NaN 개수:\", train[col].isna().sum())\n",
        "train = train.dropna(subset=label_cols)  # 라벨 NaN 제거\n",
        "\n",
        "# =========================\n",
        "# 5️⃣ 학습/예측 데이터 준비\n",
        "# =========================\n",
        "common_cols = [c for c in num_cols if c in test.columns]\n",
        "X_train = train[common_cols].copy()\n",
        "y_train = train[label_cols].copy()\n",
        "X_test  = test[common_cols].copy()\n",
        "\n",
        "print(\"[INFO] X_train:\", X_train.shape, \"y_train:\", y_train.shape, \"X_test:\", X_test.shape)\n",
        "\n",
        "# =========================\n",
        "# 6️⃣ 모델 학습/예측 (LightGBM)\n",
        "# =========================\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "    BaseClf = lgb.LGBMClassifier\n",
        "    clf_params = dict(objective=\"multiclass\", num_class=3,\n",
        "                      class_weight=\"balanced\", n_estimators=300,\n",
        "                      learning_rate=0.05, random_state=42)\n",
        "except:\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    BaseClf = RandomForestClassifier\n",
        "    clf_params = dict(n_estimators=300, class_weight=\"balanced\", random_state=42)\n",
        "\n",
        "# pipeline\n",
        "pipe = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"clf\", BaseClf(**clf_params))\n",
        "])\n",
        "\n",
        "# 학습/검증 분리\n",
        "X_tr, X_va, y_tr_all, y_va_all = train_test_split(\n",
        "    X_train, y_train, test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_train[label_cols[0]] if y_train[label_cols[0]].nunique()>1 else None\n",
        ")\n",
        "\n",
        "reports = {}\n",
        "pred_labels = {}\n",
        "pred_probas = {}\n",
        "\n",
        "for tgt in label_cols:\n",
        "    pipe.fit(X_tr, y_tr_all[tgt])\n",
        "    y_va_pred = pipe.predict(X_va)\n",
        "    reports[tgt] = classification_report(y_va_all[tgt], y_va_pred, digits=4, zero_division=0)\n",
        "    print(f\"\\n=== Validation Report: {tgt} ===\\n{reports[tgt]}\")\n",
        "\n",
        "    pred_labels[tgt] = pipe.predict(X_test)\n",
        "    try:\n",
        "        pred_probas[tgt] = pipe.predict_proba(X_test)\n",
        "    except:\n",
        "        pred_probas[tgt] = None\n",
        "\n",
        "# =========================\n",
        "# 7️⃣ 결과 저장\n",
        "# =========================\n",
        "out = pd.DataFrame(index=X_test.index)\n",
        "for tgt in label_cols:\n",
        "    out[f\"pred_{tgt}\"] = pred_labels[tgt]\n",
        "    proba = pred_probas[tgt]\n",
        "    if proba is not None and proba.ndim==2 and proba.shape[1]>=3:\n",
        "        out[f\"{tgt}_정상_%\"] = (proba[:,0]*100).round(2)\n",
        "        out[f\"{tgt}_주의_%\"] = (proba[:,1]*100).round(2)\n",
        "        out[f\"{tgt}_경고_%\"] = (proba[:,2]*100).round(2)\n",
        "\n",
        "out.to_csv(\"predictions_model_clean.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"[INFO] Saved:\", \"predictions_model_clean.csv\")\n"
      ]
    }
  ]
}